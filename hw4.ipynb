{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практическое задание\n",
    "\n",
    "<ol>\n",
    "    <li>Попробовать улучшить точность распознования образов cifar 10 сверточной нейронной сетью, рассмотренной на уроке. Приложить анализ с описанием того, что улучшает работу нейронной сети и что ухудшает.\n",
    "    </li>\n",
    "    <li>Описать также в анализе какие необоходимо внести изменения  в получившуюся у вас нейронную сеть если бы ей нужно было работать не с cifar10, а с MNIST, CIFAR100 и IMAGENET.\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniilstv/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 тренировочные примеры\n",
      "10000 тестовые примеры\n",
      "Использование data augmentation в реальном времени\n",
      "Epoch 1/15\n",
      "1563/1563 [==============================] - 822s 526ms/step - loss: 1.9065 - accuracy: 0.3114 - val_loss: 1.4637 - val_accuracy: 0.4694\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - 816s 522ms/step - loss: 1.6060 - accuracy: 0.4221 - val_loss: 1.3620 - val_accuracy: 0.5186\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - 816s 522ms/step - loss: 1.4406 - accuracy: 0.4866 - val_loss: 1.1431 - val_accuracy: 0.5974\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - 816s 522ms/step - loss: 1.3068 - accuracy: 0.5400 - val_loss: 1.0784 - val_accuracy: 0.6261\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - 820s 525ms/step - loss: 1.2246 - accuracy: 0.5684 - val_loss: 1.0037 - val_accuracy: 0.6521\n",
      "Epoch 6/15\n",
      "1563/1563 [==============================] - 811s 519ms/step - loss: 1.1633 - accuracy: 0.5957 - val_loss: 1.0584 - val_accuracy: 0.6407\n",
      "Epoch 7/15\n",
      "1563/1563 [==============================] - 816s 522ms/step - loss: 1.1126 - accuracy: 0.6096 - val_loss: 0.8841 - val_accuracy: 0.6916\n",
      "Epoch 8/15\n",
      "1563/1563 [==============================] - 813s 520ms/step - loss: 1.0613 - accuracy: 0.6294 - val_loss: 0.8571 - val_accuracy: 0.7076\n",
      "Epoch 9/15\n",
      "1563/1563 [==============================] - 813s 520ms/step - loss: 1.0238 - accuracy: 0.6430 - val_loss: 0.8200 - val_accuracy: 0.7177\n",
      "Epoch 10/15\n",
      "1563/1563 [==============================] - 815s 522ms/step - loss: 0.9888 - accuracy: 0.6560 - val_loss: 0.7751 - val_accuracy: 0.7340\n",
      "Epoch 11/15\n",
      "1563/1563 [==============================] - 817s 522ms/step - loss: 0.9657 - accuracy: 0.6618 - val_loss: 0.7627 - val_accuracy: 0.7408\n",
      "Epoch 12/15\n",
      "1563/1563 [==============================] - 818s 523ms/step - loss: 0.9373 - accuracy: 0.6709 - val_loss: 0.8056 - val_accuracy: 0.7256\n",
      "Epoch 13/15\n",
      "1563/1563 [==============================] - 817s 523ms/step - loss: 0.9121 - accuracy: 0.6809 - val_loss: 0.7266 - val_accuracy: 0.7507\n",
      "Epoch 14/15\n",
      "1563/1563 [==============================] - 826s 528ms/step - loss: 0.8883 - accuracy: 0.6925 - val_loss: 0.8330 - val_accuracy: 0.7207\n",
      "Epoch 15/15\n",
      "1563/1563 [==============================] - 814s 521ms/step - loss: 0.8675 - accuracy: 0.6993 - val_loss: 0.7150 - val_accuracy: 0.7563\n",
      "Время выполнения 662.445 минут\n",
      "   32/10000 [..............................] - ETA: 49s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniilstv/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:138: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 47s 5ms/step\n",
      "Test loss: 0.7149908617019654\n",
      "Test accuracy: 0.7562999725341797\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras # расскоментируйте эту строку, чтобы начать обучение\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "# установка параметров нейросети\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 15\n",
    "data_augmentation = True\n",
    "num_predictions = 30\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# разделение тренировочной и тестовой выборки\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'тренировочные примеры')\n",
    "print(x_test.shape[0], 'тестовые примеры')\n",
    "\n",
    "# преобразование матрицы чисел 0-9 в бинарную матрицу чисел 0-1\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# конфигурирование слоев нейросети\n",
    "model = Sequential()\n",
    "\n",
    "# слои нейросети отвественные за свертку и max-pooling\n",
    "model.add(Conv2D(100, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(128, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# # model.add(Conv2D(128, (3, 3)))\n",
    "# # model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Conv2D(200, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(100, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "# полносвязные слои нейронной сети\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# инициализация RMSprop optimizer\n",
    "# opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "#opt= keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# компиляция модели\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Не используется data augmentation')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Использование data augmentation в реальном времени')\n",
    "    # Препроцессинг и data augmentation в реальном времени:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False, \n",
    "        zca_epsilon=1e-06, \n",
    "        rotation_range=0, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "#         rescale=0.01,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # запуск data augmentation через fit\n",
    "    #datagen.fit(x_train)\n",
    "\n",
    "    # запуск data augmentation через fit_generator\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "print (\"Время выполнения {:g} минут\".format((time.clock() - start_time)/60))\n",
    "\n",
    "# сохранение модели и весов\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model.save(model_path)\n",
    "    print('сохранить обученную модель как %s ' % model_path)\n",
    "\n",
    "# проверка работы обученной модели\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовые показатели модели на уроке:\n",
    "Test loss: 1.528359656906128\n",
    "Test accuracy: 0.4399999976158142\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проведены настройки модели:\n",
    "Первоначально выкрутил ручки побольше и получил accuracy - 0.13. Явное переобучение. \n",
    "Перебором понял, что проблема была в дополнительных полносвязных слоях. Оставил один.\n",
    "После чего тюнил модель. Добрался до 0.55-0.58. В итоге упростил модель - сократил количество слоёв и поставил 15 эпох.\n",
    "\n",
    "Впроцессе тюнинга пробовал разные варианты:\n",
    "* Увеличены эпохи до 10. После 11 accuracy переставал расти.\n",
    "* Увеличил сходимость за счет повышения learning_rate до 0.001, что привело к снижению точности - вернул на 0.0001\n",
    "* Сократил помехи Dropout до 0.1. Затем расставил разные значения в зависимости от кол-ва нейронов в слое - от 0.3 до 0.1\n",
    "* Добавил сверточных слоёв с уменьшением нейронов (128, 64, 32) для повышения абстракции, разбавил их макспулингом. \n",
    "* Сначала добавил два полносвязные слои (128 и 64) перед выходом. Полносвязные слои серьёзно переобучают, снижая результат до 0.15. Оставил один слой 64.\n",
    "* Увеличил num_predictions до 50\n",
    "* Увеличил batch_size до 64\n",
    "* Добавил в слои нормализацию BatchNormalization()\n",
    "* Добавил в искажения data augmentation масштабирование изображения на 0.01 - https://keras.io/api/preprocessing/image/\n",
    "\n",
    "\n",
    "Использовал работы \n",
    "\n",
    "https://github.com/DmitriyFedorov-git/GeekBrains/blob/c89e20e1c417b42f4e21d68fc10e549f4aa7a334/Intro_NN_homework_4_CNN.ipynb\n",
    "https://github.com/rajulun/Introduction_to_neural_networks/blob/1bc070f7c9c32fd0e4ebe91856e0713188fafd94/Introduction%20to%20neural%20networks%20Lesson4.ipynb\n",
    "https://github.com/mindblower5000/neural-nets/blob/4a12ab3f518da7826b98deff1b82b3747d5730c1/hw4.ipynb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Описать также в анализе какие необоходимо внести изменения в получившуюся у вас нейронную сеть если бы ей нужно было работать не с cifar10, а с MNIST, CIFAR100 и IMAGENET.\n",
    "\n",
    "\n",
    "Во всех случая параметр выходного слоя num_classes должен соответствовать количеству выявляемых категорий.\n",
    "\n",
    "\n",
    "Для более сложеных сетов CIFAR100 и IMAGENET потребуется увеличение масштаба внутренних слоёв.\n",
    "Я бы сделал постепенное повышение уровня абстракции от слоя к слою. \n",
    "\n",
    "Для MNIST можно упростить модель: сократить слои, убрать сдвиг изображения. Этому датасету достаточно минимальных настроек сети. Входящий слой должен быть равным матрице пикселей (28 * 28). Для цветных картинок добавляется третье измерение RGB равное 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительные материалы\n",
    "\n",
    "<ol>\n",
    "    <li>https://keras.io/layers/convolutional/</li>\n",
    "    <li>https://keras.io/layers/pooling/</li>\n",
    "    <li>https://keras.io/preprocessing/image/</li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
